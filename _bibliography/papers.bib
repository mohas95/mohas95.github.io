---
---

@article{debbagh2024predictive,
selected={true},
google_scholar_id={zYLM7Y9cAGgC},
abbr={PREPRINT},
bibtex_show={true},
title={Predictive Pattern Recognition Techniques Towards Spatiotemporal Representation of Plant Growth in Simulated and Controlled Environments: A Comprehensive Review}, 
author={Mohamed Debbagh and Shangpeng Sun and Mark Lefsrud},
year={2024},
arxiv={2412.10538},
abstract={Accurate predictions and representations of plant growth patterns in simulated and controlled environments are important for addressing various challenges in plant phenomics research. This review explores various works on state-of-the-art predictive pattern recognition techniques, focusing on the spatiotemporal modeling of plant traits and the integration of dynamic environmental interactions. We provide a comprehensive examination of deterministic, probabilistic, and generative modeling approaches, emphasizing their applications in high-throughput phenotyping and simulation-based plant growth forecasting. Key topics include regressions and neural network-based representation models for the task of forecasting, limitations of existing experiment-based deterministic approaches, and the need for dynamic frameworks that incorporate uncertainty and evolving environmental feedback. This review surveys advances in 2D and 3D structured data representations through functional-structural plant models and conditional generative models. We offer a perspective on opportunities for future works, emphasizing the integration of domain-specific knowledge to data-driven methods, improvements to available datasets, and the implementation of these techniques toward real-world applications.},
preview={02.png}
}

@InProceedings{Debbagh2024Generative,
selected={true},
abbr={IAPR},
google_scholar_id={UeHWp8X0CEIC},
bibtex_show={true},
arxiv={2405.14796},
author={Debbagh, Mohamed
and Liu, Yixue
and Zheng, Zhouzhou
and Jiang, Xintong
and Sun, Shangpeng
and Lefsrud, Mark},
editor={Suen, Ching Yee
and Krzyzak, Adam
and Ravanelli, Mirco
and Trentin, Edmondo
and Subakan, Cem
and Nobile, Nicola"},
title={Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions},
booktitle={Artificial Neural Networks in Pattern Recognition},
year={2024},
publisher={Springer Nature Switzerland},
address={Cham},
pages={308--319},
abstract={A plant growth simulation can be characterized as a reconstructed visual representation of a plant or plant system. The phenotypic characteristics and plant structures are controlled by the scene environment and other contextual attributes. Considering the temporal dependencies and compounding effects of various factors on growth trajectories, we formulate a probabilistic approach to the simulation task by solving a frame synthesis and pattern recognition problem. We introduce a sequence-informed plant growth simulation framework (SI-PGS) that employs a conditional generative model to implicitly learn a distribution of possible plant representations within a dynamic scene from a fusion of low-dimensional temporal sensor and context data. Methods such as controlled latent sampling and recurrent output connections are used to improve coherence in the plant structures between frames of prediction. In this work, we demonstrate that SI-PGS is able to capture temporal dependencies and continuously generate realistic frames of plant growth.},
isbn={978-3-031-71602-7},
doi = {10.1007/978-3-031-71602-7_26},
preview={01.gif}
}

@article{debbagh2023neural,
abbr={PREPRINT},
bibtex_show={true},
google_scholar_id={d1gkVwhDpl0C},
title={Neural Radiance Fields (NeRFs): A Review and Some Recent Developments},
author={Debbagh, Mohamed},
arxiv={2305.00375},
year={2023},
doi={10.48550/arXiv.2305.00375},
abstract={Neural Radiance Field (NeRF) is a framework that represents a 3D scene in the weights of a fully connected neural network, known as the Multi-Layer Perception(MLP). The method was introduced for the task of novel view synthesis and is able to achieve state-of-the-art photorealistic image renderings from a given continuous viewpoint. NeRFs have become a popular field of research as recent developments have been made that expand the performance and capabilities of the base framework. Recent developments include methods that require less images to train the model for view synthesis as well as methods that are able to generate views from unconstrained and dynamic scene representations}
}

@article{debbagh2023learning,
abbr={PREPRINT},
bibtex_show={true},
google_scholar_id={u-x6o8ySG0sC},
title={Learning structured output representations from attributes using deep conditional generative models},
author={Debbagh, Mohamed},
arxiv={2305.00980},
year={2023},
doi={10.48550/arXiv.2305.00980},
abstract={Structured output representation is a generative task explored in computer vision that often times requires the mapping of low dimensional features to high dimensional structured outputs. Losses in complex spatial information in deterministic approaches such as Convolutional Neural Networks (CNN) lead to uncertainties and ambiguous structures within a single output representation. A probabilistic approach through deep Conditional Generative Models (CGM) is presented by Sohn et al. in which a particular model known as the Conditional Variational Auto-encoder (CVAE) is introduced and explored. While the original paper focuses on the task of image segmentation, this paper adopts the CVAE framework for the task of controlled output representation through attributes. This approach allows us to learn a disentangled multimodal prior distribution, resulting in more controlled and robust approach to sample generation. In this work we recreate the CVAE architecture and train it on images conditioned on various attributes obtained from two image datasets; the Large-scale CelebFaces Attributes (CelebA) dataset and the Caltech-UCSD Birds (CUB-200-2011) dataset. We attempt to generate new faces with distinct attributes such as hair color and glasses, as well as different bird species samples with various attributes. We further introduce strategies for improving generalized sample generation by applying a weighted term to the variational lower bound.},
preview={03.png}
}

@inproceedings{debbagh2018development,
abbr={ICPA},
bibtex_show={true},
google_scholar_id={qjMakFHDy7sC},
title={Development of a Wireless Sensor Network for Passive in situ Measurement of Soil CO2 Gas Emissions in the Agriculture Landscape},
author={Debbagh, M and Adamchuk, V and Madramootoo, C and Whalen, J},
booktitle={Proceedings of the 14th International Conference on Precision Agriculture, Montreal, QC, Canada},
pages={24--27},
year={2018}
}

@article{adamchuk2023instrumentation,
bibtex_show={true},
google_scholar_id={2osOgNQ5qMEC},
title={Instrumentation for on-the-spot measurement of soil health indicators},
author={Adamchuk, V and Lan, J and Abdalla, K and Carlson, P Dias and Debbagh, M and Madramootoo, C and Kvezereli, B},
journal={Precision agriculture'23},
pages={821--829},
year={2023},
doi={10.3920/978-90-8686-947-3_103},
publisher={Wageningen Academic},
address = "Leiden, The Netherlands",
isbn = "9789086869473",
abstract={This paper reviews several recent developments in integrated sensor systems for in situ measurements and monitoring of soil health indicators, such as changes in CO 2 concentration near the surface or within the pore space. These measurements are done in conjunction with traditional measurements of soil temperature and water content. In addition, some of these systems detect characteristics, such as penetration impedance and friction. These sensor systems complement existing on-the-spot soil analyzers for soil pH, N, P, K, hyperspectral reflectance, digital microscopy, as well as the entire fleet of proximal soil sensing platforms.}
}

@article{ZHENG2025125962,
bibtex_show={true},
google_scholar_id={IjCSPb-OGe4C},
abbr={ESWA},
title = {Graph-Transformer with spatial-spectral features fusion for hyperspectral image classification},
journal = {Expert Systems with Applications},
volume = {264},
pages = {125962},
year = {2025},
issn = {0957-4174},
doi = {10.1016/j.eswa.2024.125962},
url = {https://www.sciencedirect.com/science/article/pii/S095741742402829X},
author = {Zhouzhou Zheng and Mohamed Debbagh and Xuehai Zhou and Shangpeng Sun and Yuxiang Huang},
keywords = {Hyperspectral image classification, Graph-Transformer module, Dual branches, Feature fusion},
abstract = {Hyperspectral image (HSI) classification plays an important role in interpreting semantics and pixel information. Recently, the graph convolution network (GCN) and vision transformer (ViT) have shown impressive classification capabilities in HSI analysis. Each method offers unique advantages: GCN focuses on local neighborhood features, whereas ViT emphasizes long-range dependencies global features. Existing studies integrated the two methods by serial or parallel for HSI analysis, however, they fell short in deeply fusing the two approaches. To address the challenge, a Graph-Transformer module (GTM) is proposed, which effectively combines local neighborhood features and long-range dependencies global features. Moreover, a spectral feature extraction branch is introduced to enhance spectral learning. Finally, the spatial branch consisting of GTM and spectral branch are fused to complete HSI classification. Experimental results showed that our proposed Graph-Transformer with spatial-spectral features fusion network (GTS2F2Net) outperformed other state-of-the-art methods on three public datasets. Specifically, it achieved overall accuracy (OA) of 99.31%, 99.69%, and 97.17% on Salinas Valley (SA), Pavia University (PU), Houston 2013, respectively.}
}

@inproceedings{brousseauanimal,
abbr={CSBE},
bibtex_show={true},
google_scholar_id={9yKSN-GCB0IC},
title={Animal-Waste Based Organic Liquid Fertilizer as a Replacement for Synthetic Nitrogen in Basil Production: A Case Study},
author={Brousseau, Vincent Desaulniers and Leroux, David and Martel, Simone and Tikasz, Peter and Debbagh, Mohamed and Gigu{\`e}re, Thomas and Tazi, Ilies and MacPherson, Sarah and Lefsrud, Mark G},
booktitle={CSBE/SCGAB AGM and Technical Conference 2022},
year={2022},
url={https://www.researchgate.net/publication/362344160_Animal-Waste_Based_Organic_Liquid_Fertilizer_as_a_Replacement_for_Synthetic_Nitrogen_in_Basil_Production_A_Case_Study},
abstract={Decreasing inorganic N dependency can be an economical an environmental solution that prepares hydroponic producers for the next era of agriculture as input costs rise. To enable sustainable growth for the hydroponic crop production industry, newly developed technologies that use locally sourced organic N fertilizer products are needed. In this study, animal waste from chicken and insect were transformed into a nitrate-rich organic liquid fertilizer (OLF) using a proprietary bioreactor. The animal-waste derived OLF was injected into two separate hydroponic production systems where basil plants were grown. The two separate locations included a controlled environment and a greenhouse. Yield was compared to an inorganic fertilizer control as well as a 50:50 OLF:inorganic solution (OLF+). Basil plants grown with OLF did not show any significant difference in above ground fresh mass versus plants grown with inorganic N fertilizer in both production systems. A consistent but non-significant 10% increase was observed in above ground fresh mass yield for the OLF+ treatment. OLF may be attractive to hydroponic producers interested in using alternatives to conventional hydroponic fertilizer products. This frass derived OLF can enable sustainable growth for urban food-producing systems by increasing fertilizer use efficiency.}
}
